{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "frocasting, fillnawith 0",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1g_3bzAmLV1SoZ-EFUr65wNPg-l0yz9YR",
      "authorship_tag": "ABX9TyOwswYWFFEr6/5evKNc/A40",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varshapande/Project-of-machinelearning-/blob/main/frocasting%2C_fillnawith_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnU6ipdHeyeY"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "from datetime import date, datetime\n",
        "import time\n",
        "import calendar\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMnIfFREy9f1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOfFDKT4fI9d"
      },
      "source": [
        "train1 = pd.read_csv('/content/drive/MyDrive/forcastingtrain (1).csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/forcastingtest.csv')\n",
        "oil = pd.read_csv('/content/drive/MyDrive/oil.csv')\n",
        "stores = pd.read_csv('/content/drive/MyDrive/stores.csv')\n",
        "holidays = pd.read_csv('/content/drive/MyDrive/holidays_events.csv')\n",
        "transactions = pd.read_csv('/content/drive/MyDrive/transactions.csv.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMatbYX_kdms"
      },
      "source": [
        "train1.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7q9aEy_oN8H"
      },
      "source": [
        "### here train is the concat of train1 and test "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz42n2a_oOaB"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJpLPXjVfJH4"
      },
      "source": [
        "train = pd.concat([train1,test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhihpjjHfJSR"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HccPVf9TfqeJ"
      },
      "source": [
        "stores.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhx5OfGhftsT"
      },
      "source": [
        "holidays.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLedtts5fvOW"
      },
      "source": [
        "oil.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQv236ctexkL"
      },
      "source": [
        "merge_data = train.merge(oil, on='date', how='left')\n",
        "merge_data = merge_data.merge(holidays, on='date', how='left')\n",
        "merge_data = merge_data.merge(stores, on='store_nbr', how='left')\n",
        "merge_data = merge_data.merge(transactions, on=['date', 'store_nbr'], how='left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcXnrZK9knbe"
      },
      "source": [
        "merge_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGfQC-vaf4wK"
      },
      "source": [
        "\n",
        "merge_data['date'] = pd.to_datetime(merge_data['date']).dt.date\n",
        "merge_data['year'] = pd.to_datetime(merge_data['date']).dt.year\n",
        "merge_data['month'] = pd.to_datetime(merge_data['date']).dt.month\n",
        "merge_data['day'] = pd.to_datetime(merge_data['date']).dt.day"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cglaXbOWgtTD"
      },
      "source": [
        "merge_data.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8SQ1MmegtVp"
      },
      "source": [
        "def core(dataset,threshold):\n",
        "    col = set()\n",
        "    cormatrix = dataset.corr()\n",
        "    for i in range(len(cormatrix.columns)):\n",
        "     for j in range(i):\n",
        "        if abs(cormatrix.iloc[i,j])>threshold:\n",
        "             colname = cormatrix.columns[i]\n",
        "             col.add(colname)\n",
        "    return col"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWFtojkejZXQ"
      },
      "source": [
        "corrfeature = core(merge_data,.8)\n",
        "corrfeature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PovZ74DCo7fG"
      },
      "source": [
        "### here I am dropping highly corr features if i will not drop i will encode them by doing before str opertaion."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUq23XEhpFfJ"
      },
      "source": [
        "df = merge_data.drop(columns =['dcoilwtico', 'month', 'year','sales',])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8wtsaPNkLn7"
      },
      "source": [
        "df.isnull().mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt_MT6w9kjgZ"
      },
      "source": [
        "#import calendar\n",
        "#merge_data['month'] = merge_data['month'].apply(lambda x:calendar.month_abbr[x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk9aw3BNkjjj"
      },
      "source": [
        "#merge_data['year']= merge_data['year'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV4cZduhkjnt"
      },
      "source": [
        "df['day']= df['day'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYjlAA_qnnly"
      },
      "source": [
        "numer = df.select_dtypes(['int64','float64'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mPwgAuynnwU"
      },
      "source": [
        "numermiss = [var for var in numer if numer[var].isnull().sum()>0]\n",
        "numermiss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfXem9u3nnz2"
      },
      "source": [
        "## filling missing value with the same name \n",
        "def whole(df,var):\n",
        "    #mean = df[var].mean()\n",
        "    df[var] = df[var].fillna(0)\n",
        "    #median = df[var].median()\n",
        "    #extreme = df[var].mean()+3*df[var].std()\n",
        "    #randomsample = df[var].dropna().sample(df[var].isnull().sum(),random_state = 0)\n",
        "    #df[var]= df[var].fillna(median)\n",
        "    #df[var] = df[var].fillna(extreme)\n",
        "    #df[var+'rand']  = df[var]\n",
        "   # randomsample.index = df[df[var].isnull()].index\n",
        "    #df.loc[df[var].isnull(),var+'rand'] = randomsample\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg-eIdBwqzjW"
      },
      "source": [
        "whole(df,'onpromotion')\n",
        "whole(df,'transactions')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLeY7VfAStr6"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ox7uEBOrLiu"
      },
      "source": [
        "desvar = [var for var in numer if len(df[var].unique())< 25 ]\n",
        "desvar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX3Q0OqirI-C"
      },
      "source": [
        "continous = [var for var in numer if var not in desvar and var not in   ['id']]\n",
        "continous"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVXtcLv-rlfv"
      },
      "source": [
        "def fighist(df,var):\n",
        "     df[var].hist(bins = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9ecG8qprlqF"
      },
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "sns.set()\n",
        "for i,var in enumerate (desvar):\n",
        "    plt.subplot(4,3,i+1)\n",
        "    fighist(df,var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x64Nerp7r0zy"
      },
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "sns.set()\n",
        "for i,var in enumerate (continous):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    fighist(df,var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVpmW7PTr04n"
      },
      "source": [
        "import scipy.stats as stat\n",
        "import pylab\n",
        "def pltdata(df,var):\n",
        "    plt.figure(figsize = (5,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    df[var].hist()\n",
        "    plt.subplot(1,2,2)\n",
        "    stat.probplot(df[var],dist = 'norm',plot = pylab)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v0Ol_uir1DM"
      },
      "source": [
        "for i,var in enumerate(desvar):\n",
        "    \n",
        "    pltdata(df,var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z31bwfnxsA4d"
      },
      "source": [
        "for i,var in enumerate(continous):\n",
        "    \n",
        "    pltdata(df,var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0hjaacysA_X"
      },
      "source": [
        "def logtran(df,var):\n",
        "    df[var] = np.log(df[var])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os8Vg_wasWtg"
      },
      "source": [
        "for var in continous:\n",
        "    if 0 in df[var].unique():\n",
        "        pass\n",
        "    else:\n",
        "        logtran(df,var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2G0bcAwsW3B"
      },
      "source": [
        "##again see their QQ plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRWvGNBjsiGB"
      },
      "source": [
        "for i,var in enumerate(continous):\n",
        "    \n",
        "    pltdata(df,var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M51hqpXDsiJY"
      },
      "source": [
        "import warnings \n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLPSwHwnuATr"
      },
      "source": [
        "def fig(df,var):\n",
        "   sns.boxplot(var,data = df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9VSc0vevPKV"
      },
      "source": [
        "plt.figure(figsize = (10,5))\n",
        "sns.set()\n",
        "for i,var in enumerate (desvar):\n",
        "    plt.subplot(8,2,i+1)\n",
        "    fig(df,var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TT0YR3HvUmV"
      },
      "source": [
        "plt.figure(figsize = (10,5))\n",
        "sns.set()\n",
        "for i,var in enumerate (continous):\n",
        "    plt.subplot(8,2,i+1)\n",
        "    fig(df,var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm3bsXk2vUve"
      },
      "source": [
        "### here outliears in only onpromotion and it is continous so here method additional of desvar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18rtMLTjvh_R"
      },
      "source": [
        "def continu(df,var):\n",
        "  upper=df[var].mean()+3*df[var].std()\n",
        "  lower = df[var].mean()-3*df[var].std()\n",
        "  iqr = df[var].quantile(.75) -df[var].quantile(.25)\n",
        "  lbd = df[var].quantile(.25)-(iqr*3)\n",
        "  ubd = df[var].quantile(.75)+(iqr*3)\n",
        "  df.loc[df[var]>=ubd,var]=ubd\n",
        "  print(upper)\n",
        "  print(lower)\n",
        "  print(iqr)\n",
        "  print (lbd)\n",
        "  print(ubd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByGmrPboviLv"
      },
      "source": [
        "for var in continous: \n",
        "  continu(df,var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jwtbkEew7y_"
      },
      "source": [
        "plt.figure(figsize = (10,5))\n",
        "sns.set()\n",
        "for i,var in enumerate (continous):\n",
        "    plt.subplot(8,2,i+1)\n",
        "    fig(df,var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb_b5Ah8x1nw"
      },
      "source": [
        "### same process do for train1sales. check graph then outliears and then remove. as it is descrete. check it is desvar or continous. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ9P3mPQx1wb"
      },
      "source": [
        "fighist(train1,'sales')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18i4_Blzx1zl"
      },
      "source": [
        "fig(train1,'sales')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix030_avx12a"
      },
      "source": [
        " continu(train1,'sales')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZB0QGwLzOWL"
      },
      "source": [
        "fig(train1,'sales')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY2WsFntzhX-"
      },
      "source": [
        "### above prpcess was to remove outliers in sales. but in original data. beacuse it is target."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5Q3UiI-ztCy"
      },
      "source": [
        "catvar = df.select_dtypes(include = 'object') \n",
        "catvar\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J479k2V2Ezho"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhvSM08iz5nx"
      },
      "source": [
        "catvarfill = [var for var in catvar if catvar[var] .isnull().sum()>0]\n",
        "catvarfill"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHdMwLuTztHZ"
      },
      "source": [
        "for var in catvarfill:\n",
        "   catvar[var].fillna(0,inplace = True)\n",
        "   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVwEX5ZEXJxn"
      },
      "source": [
        "df['type_x'].dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ-mmBRHWo8-"
      },
      "source": [
        "for var in catvarfill:\n",
        " df[var] = df[var].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLiNwD-MXXUE"
      },
      "source": [
        "df['type_x'].dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2OoygFHztL5"
      },
      "source": [
        "df.update(catvar)\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU57bhmJztO2"
      },
      "source": [
        "y = train1['sales']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gypYVJ4Z4wk8"
      },
      "source": [
        "df['sales'] = y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqZ_GH0m6mXD"
      },
      "source": [
        "df.head(6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9T1FCV24dLz"
      },
      "source": [
        "x = df.groupby('family')['sales'].mean().sort_values().index\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmtO-Vxa7nDR"
      },
      "source": [
        "x = df.groupby('type_x')['sales'].mean().sort_values().index\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b07L3oPEXhY0"
      },
      "source": [
        "df['type_x'] = np.where(df['type_x']=='Holiday',1,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13go_f1j7nL7"
      },
      "source": [
        "x = df.groupby('locale')['sales'].mean().sort_values().index\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IrKwTSGXuwy"
      },
      "source": [
        "df['locale'] = np.where(df['locale']=='National',1,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3fpfeKk7nWl"
      },
      "source": [
        "x = df.groupby('locale_name')['sales'].mean().sort_values().index\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-6B5jUNYYjj"
      },
      "source": [
        "df['locale_name'] = np.where(df['locale_name']=='Ecuador',1,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PppnT9Hy8DlA"
      },
      "source": [
        "\n",
        "x = df.groupby('description')['sales'].mean().sort_values().index\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYUL7R4-Yy3A"
      },
      "source": [
        "top = ['Primer dia del ano','Carnaval']\n",
        "for label in top:\n",
        " df[label] = np.where(df['description']==label,1,0)\n",
        "### now drop description columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz0ZULaB8Dr9"
      },
      "source": [
        "x = df.groupby('transferred')['sales'].mean().sort_values().index\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZaWxJVr8VbQ"
      },
      "source": [
        "x = df.groupby('city')['sales'].mean().sort_values().index\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqj_5Sfe8eK-"
      },
      "source": [
        "x = df.groupby('state')['sales'].mean().sort_values().index\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o7Dq7b48eUK"
      },
      "source": [
        "x = df.groupby('type_y')['sales'].mean().sort_values().index\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsIXT3SeBfPU"
      },
      "source": [
        "anotherone = ['family', \n",
        "        'city', 'state', 'type_y']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlDRPlRo66XA"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "for var in anotherone :\n",
        " labels = le.fit_transform(df[var])\n",
        " df[var] = labels\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUhkv2BXHhN6"
      },
      "source": [
        "### here days should be in the form of monday = 1 and tuesday = 2 and sunday = 7\n",
        "eu = df.day.unique()\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "od = OrdinalEncoder(categories = [eu])\n",
        "labels = od.fit_transform(df[['day']])\n",
        "df['day'] = labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCn7UFQ7rR6m"
      },
      "source": [
        "df.tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbnI1X9ECSHy"
      },
      "source": [
        "transfer = pd.get_dummies(df['transferred'],drop_first = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tLis-lOCSOO"
      },
      "source": [
        "df1 = df.drop(columns =['transferred','date','description'],axis = 1)\n",
        "df1 = pd.concat([df1,transfer],axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp0UsTViCSUd"
      },
      "source": [
        "df1.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY5vf_ScI2I2"
      },
      "source": [
        "n = len(train1)\n",
        "df2 = df1.drop(columns = 'sales',axis = 1)\n",
        "Y = df1['sales']\n",
        "xtrain = df2[:n]\n",
        "xtest = df2[n:]\n",
        "ytrain = Y[:n]\n",
        "ytrain = ytrain.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDBR1bu7K1W-"
      },
      "source": [
        "xtrain.isnull().sum()\n",
        "ytrain.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsGGhxOgJ8fC"
      },
      "source": [
        "print(xtrain.shape)\n",
        "print(xtest.shape)\n",
        "print(ytrain.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHcHQpmjUlmI"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "xtrain = sc.fit_transform(xtrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPwJQmCjKjZB"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lr = LinearRegression()\n",
        "lr.fit(xtrain,ytrain)\n",
        "ypred = lr.predict(xtest)\n",
        "ypredict = ypred.astype(int)\n",
        "ypredict.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlBFf6r8Lxck"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "rd = Ridge()\n",
        "rd.fit(xtrain,ytrain)\n",
        "ypred1 = rd.predict(xtest)\n",
        "YP1 = ypred1.astype(int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtO3f17iLxpF"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "ls = Lasso()\n",
        "ls.fit(xtrain,ytrain)\n",
        "ypred2 = ls.predict(xtest)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIolBkxBQFYM"
      },
      "source": [
        "from sklearn.ensemble import BaggingRegressor ,GradientBoostingRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSZS1AgkQTud"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rancl = RandomForestRegressor(n_estimators= 100,criterion = 'mse',max_features = 'sqrt',min_samples_leaf = 10,random_state= 100)\n",
        "rancl.fit(xtrain,ytrain)\n",
        "ybest22 = rancl.predict(xtest)\n",
        "ybest22 = ybest22.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlGvfRujWZ1J"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rancl = RandomForestRegressor(n_estimators= 100,criterion = 'mse',max_features = 'sqrt',min_samples_leaf = 10,random_state= 100)\n",
        "rancl.fit(xtrain,ytrain)\n",
        "ybest22 = rancl.predict(xtest)\n",
        "ybest22 = ybest22.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFI0EuvNWY-2"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rancl = RandomForestRegressor(n_estimators= 100,criterion = 'mse',max_features = 'sqrt',min_samples_leaf = 10,random_state= 100)\n",
        "rancl.fit(xtrain,ytrain)\n",
        "ybest22 = rancl.predict(xtest)\n",
        "ybest22 = ybest22.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ4KdTsIsfTz"
      },
      "source": [
        "import xgboost as xgb\n",
        "xgbr=xgb.XGBRegressor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnuLYDi4LbeH"
      },
      "source": [
        "xgbtrain = xgb.DMatrix(xtrain)\n",
        "xgbtest = xgb.DMatrix(xtest)\n",
        "#yxgb =    xgb.DMatrix(ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIfDwryhLhIJ"
      },
      "source": [
        "#xgbr.fit(xtrain,ytrain)\n",
        "#ypredxgb = xgbr.predict(xgbtest)\n",
        "#ypredxgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh_6nEXZDi9z"
      },
      "source": [
        "#### from here start hyperparametertununig\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON9kLlK9shZb"
      },
      "source": [
        "## Hyper Parameter Optimization for randomforest regressor\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 10)]\n",
        "#max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(random_grid)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "___3RGtiNm0e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnRAfW5IynC9"
      },
      "source": [
        "from datetime import datetime\n",
        "d1 = datetime.now()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuRa3uMkuZ_z"
      },
      "source": [
        "def timer(start_time = None):\n",
        "  if not start_time :\n",
        "     start_time = datetime.now()\n",
        "     return start_time\n",
        "  elif start_time:\n",
        "    thour,temp_sec= divmod((datetime.now()-start_time).total_seconds(),3600)\n",
        "    tmin,tsec = divmod(temp_sec,60)\n",
        "    print('\\n'%(thour,tmin,round(tsec,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um42L9v_SFnm"
      },
      "source": [
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rf = RandomForestRegressor()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 5, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfqtwXJFyPmP"
      },
      "source": [
        "#start_time = timer(None)\n",
        "#rf_random.fit(xtrain, ytrain)\n",
        "#timer(start_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TWuXexJPkzD"
      },
      "source": [
        "#### try to use lstm model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FiBH30zshhN"
      },
      "source": [
        "### I should do work with hyperturning of randomforest beacuse in case of xgboost required to remove error or same features names "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnozQcavLha7"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kfold_validation = KFold(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHTQFv_kLk8W"
      },
      "source": [
        "from sklearn. model_selection import cross_val_score\n",
        "result = cross_val_score(rancl,xtrain,ytrain,cv = kfold_validation)\n",
        "print(result)\n",
        "print(np.mean(result))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ncd356PsLm4l"
      },
      "source": [
        "submittest = pd.concat([test['id'],pd.DataFrame(ybest22)],axis=1)\n",
        "submittest.columns = ['id','sales']\n",
        "submittest.to_csv('sample_submission.csv',index = False)\n",
        "submittest"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}